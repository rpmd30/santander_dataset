{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0025c350-ef3b-4e81-8dfa-9f339814bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35712b6a-cc89-4f6d-ac60-0fc7bc5b459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=5\n",
    "BATCH_SIZE=32\n",
    "LEARNING_RATE=.003\n",
    "df = pd.read_csv('dataset/train.csv')\n",
    "\n",
    "y = df['target'].values\n",
    "\n",
    "del df['target']\n",
    "del df['ID_code']\n",
    "X = df.values\n",
    "\n",
    "X = normalize(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e93097-bba7-46f8-ada6-c9211337d1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([134898.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,      0.,  15102.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84434568-cabc-42e8-8ed6-7051c250cc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[:10]:[0 0 0 0 0 0 0 0 0 0]\n",
      "X_train[:10]:[[ 0.04854681 -0.00849624  0.08182677 ...  0.04909309  0.05460884\n",
      "  -0.00025026]\n",
      " [ 0.065986    0.02427497  0.06952132 ...  0.04920631  0.08961166\n",
      "  -0.15545063]\n",
      " [ 0.08592794  0.00822055  0.07572142 ...  0.0496339   0.1111114\n",
      "  -0.00618702]\n",
      " ...\n",
      " [ 0.07526229 -0.03055509  0.05430756 ...  0.04669336  0.08135884\n",
      "  -0.12464366]\n",
      " [ 0.0494931   0.02098225  0.08158563 ...  0.05685056  0.10454971\n",
      "  -0.05314423]\n",
      " [ 0.08161268  0.01909418  0.03263414 ...  0.06040893  0.09021432\n",
      "   0.04775095]]\n",
      "y_test[:10]:[1 0 0 0 0 0 0 0 0 1]\n",
      "X_test[:10]:[[ 0.07557821 -0.04973809  0.07112618 ...  0.05711297  0.09477299\n",
      "  -0.00348768]\n",
      " [ 0.0518955  -0.01992334  0.04194749 ...  0.04805991  0.09716992\n",
      "  -0.0303703 ]\n",
      " [ 0.05139497 -0.03295939  0.06464605 ...  0.04133958  0.10531542\n",
      "  -0.06594055]\n",
      " ...\n",
      " [ 0.0500989  -0.03718965  0.0686013  ...  0.05528441  0.12844258\n",
      "   0.05017534]\n",
      " [ 0.07863138 -0.00668167  0.07998692 ...  0.05389254  0.07264509\n",
      "  -0.14843813]\n",
      " [ 0.03644614 -0.01555318  0.03868035 ...  0.05105044  0.10536478\n",
      "  -0.03938734]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train[:10]:{y_train[:10]}\")\n",
    "print(f\"X_train[:10]:{X_train[:10]}\")\n",
    "\n",
    "print(f\"y_test[:10]:{y_test[:10]}\")\n",
    "print(f\"X_test[:10]:{X_test[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8a74c8-2def-4cb6-bdc9-0b19b68e2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx].astype(np.float32), self.y[idx].astype(np.float32)\n",
    "\n",
    "dataset_train = TransactionsDataset(X_train,y_train)\n",
    "dataset_test = TransactionsDataset(X_test,y_test)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train,batch_size=BATCH_SIZE)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e85d896-635c-47d8-b0e3-93e2f42dbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.linear_0 = torch.nn.Linear(200,1024)\n",
    "        self.batch_norm_0 = torch.nn.BatchNorm1d(1024)\n",
    "        self.relu_0 = torch.nn.ReLU(1024)\n",
    "        self.linear_1 = torch.nn.Linear(1024,2048)\n",
    "        self.batch_norm_1 = torch.nn.BatchNorm1d(2048)\n",
    "        self.relu_1 = torch.nn.ReLU(2048)\n",
    "        self.linear_2 = torch.nn.Linear(2048,1024)\n",
    "        self.batch_norm_2 = torch.nn.BatchNorm1d(1024)\n",
    "        self.relu_2 = torch.nn.ReLU(1024)\n",
    "        self.dr_2 = torch.nn.Dropout1d(.2)\n",
    "        self.linear_3 = torch.nn.Linear(1024,512)\n",
    "        self.batch_norm_3 = torch.nn.BatchNorm1d(512)\n",
    "        self.relu_3 = torch.nn.ReLU(512)\n",
    "        self.linear_4 = torch.nn.Linear(512,256)\n",
    "        self.batch_norm_4 = torch.nn.BatchNorm1d(256)\n",
    "        self.relu_4 = torch.nn.ReLU(256)\n",
    "        self.linear_5 = torch.nn.Linear(256,128)\n",
    "        self.batch_norm_5 = torch.nn.BatchNorm1d(128)\n",
    "        self.relu_5 = torch.nn.ReLU(128)\n",
    "        self.dr_5 = torch.nn.Dropout1d(.2)\n",
    "        self.linear_6 = torch.nn.Linear(128,64)\n",
    "        self.batch_norm_6 = torch.nn.BatchNorm1d(64)\n",
    "        self.relu_6 = torch.nn.ReLU(64)\n",
    "        self.linear_7 = torch.nn.Linear(64,16)\n",
    "        self.relu_7 = torch.nn.ReLU(16)\n",
    "        self.batch_norm_7 = torch.nn.BatchNorm1d(16)\n",
    "        self.linear_8 = torch.nn.Linear(16,1)\n",
    "        self.relu_8 = torch.nn.ReLU(1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear_0(x)\n",
    "        x = self.batch_norm_0(x)\n",
    "        x = self.relu_0(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.dr_2(x)\n",
    "        x = self.linear_3(x)\n",
    "        x = self.batch_norm_3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.linear_4(x)\n",
    "        x = self.batch_norm_4(x)\n",
    "        x = self.relu_5(x)\n",
    "        x = self.dr_5(x)\n",
    "        x = self.linear_5(x)\n",
    "        x = self.batch_norm_5(x)\n",
    "        x = self.relu_6(x)\n",
    "        x = self.linear_6(x)\n",
    "        x = self.batch_norm_6(x)\n",
    "        x = self.relu_7(x)\n",
    "        x = self.linear_7(x)\n",
    "        x = self.batch_norm_7(x)\n",
    "        x = self.relu_8(x)\n",
    "        x = self.linear_8(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = Model()\n",
    "model.to(device)\n",
    "checkpoint = None\n",
    "# we need to add some weight to the success values because the labels are very unbalanced\n",
    "loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([17.0/18.0]))\n",
    "loss.to(device)\n",
    "min_loss = None\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "198484b5-c39a-430a-95de-65a8a89a1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, min_loss, checkpoint):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        y = y.unsqueeze(1)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    if not min_loss:\n",
    "        min_loss = loss\n",
    "        checkpoint = model\n",
    "    if loss.item() < min_loss.item():\n",
    "        min_loss = loss\n",
    "        checkpoint = model\n",
    "    print(f\"Checkpoint loss:{min_loss:>7f}\")\n",
    "    return model, optimizer, min_loss, checkpoint\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    preds = []\n",
    "    targets = []\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y = y.unsqueeze(1)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            pred = torch.sigmoid(pred)\n",
    "            pred = torch.round(pred)\n",
    "            correct += (pred == y).sum().item()\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            targets.extend(y.cpu().numpy())\n",
    "    print(classification_report(targets,preds))\n",
    "            \n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34242941-e1f7-47fc-b6f2-68df0bf4844e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.549609  [   32/150000]\n",
      "loss: 0.684593  [ 3232/150000]\n",
      "loss: 0.169046  [ 6432/150000]\n",
      "loss: 0.360723  [ 9632/150000]\n",
      "loss: 0.387753  [12832/150000]\n",
      "loss: 0.302044  [16032/150000]\n",
      "loss: 0.304138  [19232/150000]\n",
      "loss: 0.313504  [22432/150000]\n",
      "loss: 0.225842  [25632/150000]\n",
      "loss: 0.205079  [28832/150000]\n",
      "loss: 0.330772  [32032/150000]\n",
      "loss: 0.346080  [35232/150000]\n",
      "loss: 0.502486  [38432/150000]\n",
      "loss: 0.331379  [41632/150000]\n",
      "loss: 0.166365  [44832/150000]\n",
      "loss: 0.367918  [48032/150000]\n",
      "loss: 0.150323  [51232/150000]\n",
      "loss: 0.183928  [54432/150000]\n",
      "loss: 0.184389  [57632/150000]\n",
      "loss: 0.176331  [60832/150000]\n",
      "loss: 0.223438  [64032/150000]\n",
      "loss: 0.327611  [67232/150000]\n",
      "loss: 0.187701  [70432/150000]\n",
      "loss: 0.602486  [73632/150000]\n",
      "loss: 0.287441  [76832/150000]\n",
      "loss: 0.175462  [80032/150000]\n",
      "loss: 0.193282  [83232/150000]\n",
      "loss: 0.421393  [86432/150000]\n",
      "loss: 0.507346  [89632/150000]\n",
      "loss: 0.161576  [92832/150000]\n",
      "loss: 0.382286  [96032/150000]\n",
      "loss: 0.266609  [99232/150000]\n",
      "loss: 0.283739  [102432/150000]\n",
      "loss: 0.182885  [105632/150000]\n",
      "loss: 0.251722  [108832/150000]\n",
      "loss: 0.273185  [112032/150000]\n",
      "loss: 0.341175  [115232/150000]\n",
      "loss: 0.167188  [118432/150000]\n",
      "loss: 0.350952  [121632/150000]\n",
      "loss: 0.158357  [124832/150000]\n",
      "loss: 0.613387  [128032/150000]\n",
      "loss: 0.155051  [131232/150000]\n",
      "loss: 0.270064  [134432/150000]\n",
      "loss: 0.229505  [137632/150000]\n",
      "loss: 0.363939  [140832/150000]\n",
      "loss: 0.206422  [144032/150000]\n",
      "loss: 0.263143  [147232/150000]\n",
      "Checkpoint loss:0.370393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95     45004\n",
      "         1.0       0.81      0.10      0.17      4996\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.86      0.55      0.56     50000\n",
      "weighted avg       0.90      0.91      0.87     50000\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.241254 \n",
      "\n",
      "loss: 0.288350  [   32/150000]\n",
      "loss: 0.709673  [ 3232/150000]\n",
      "loss: 0.109452  [ 6432/150000]\n",
      "loss: 0.381715  [ 9632/150000]\n",
      "loss: 0.407079  [12832/150000]\n",
      "loss: 0.393842  [16032/150000]\n",
      "loss: 0.291665  [19232/150000]\n",
      "loss: 0.299599  [22432/150000]\n",
      "loss: 0.158297  [25632/150000]\n",
      "loss: 0.180781  [28832/150000]\n",
      "loss: 0.273849  [32032/150000]\n",
      "loss: 0.252203  [35232/150000]\n",
      "loss: 0.557563  [38432/150000]\n",
      "loss: 0.265835  [41632/150000]\n",
      "loss: 0.178610  [44832/150000]\n",
      "loss: 0.372326  [48032/150000]\n",
      "loss: 0.142691  [51232/150000]\n",
      "loss: 0.168539  [54432/150000]\n",
      "loss: 0.193544  [57632/150000]\n",
      "loss: 0.175000  [60832/150000]\n",
      "loss: 0.152591  [64032/150000]\n",
      "loss: 0.328961  [67232/150000]\n",
      "loss: 0.274530  [70432/150000]\n",
      "loss: 0.451801  [73632/150000]\n",
      "loss: 0.219454  [76832/150000]\n",
      "loss: 0.186199  [80032/150000]\n",
      "loss: 0.183503  [83232/150000]\n",
      "loss: 0.396425  [86432/150000]\n",
      "loss: 0.402678  [89632/150000]\n",
      "loss: 0.096710  [92832/150000]\n",
      "loss: 0.372621  [96032/150000]\n",
      "loss: 0.220668  [99232/150000]\n",
      "loss: 0.251492  [102432/150000]\n",
      "loss: 0.191494  [105632/150000]\n",
      "loss: 0.226752  [108832/150000]\n",
      "loss: 0.286528  [112032/150000]\n",
      "loss: 0.424380  [115232/150000]\n",
      "loss: 0.199913  [118432/150000]\n",
      "loss: 0.326279  [121632/150000]\n",
      "loss: 0.122774  [124832/150000]\n",
      "loss: 0.730152  [128032/150000]\n",
      "loss: 0.157787  [131232/150000]\n",
      "loss: 0.219305  [134432/150000]\n",
      "loss: 0.247676  [137632/150000]\n",
      "loss: 0.238869  [140832/150000]\n",
      "loss: 0.186622  [144032/150000]\n",
      "loss: 0.208995  [147232/150000]\n",
      "Checkpoint loss:0.290245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95     45004\n",
      "         1.0       0.83      0.09      0.16      4996\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.87      0.54      0.56     50000\n",
      "weighted avg       0.90      0.91      0.87     50000\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.240597 \n",
      "\n",
      "loss: 0.336582  [   32/150000]\n",
      "loss: 0.579765  [ 3232/150000]\n",
      "loss: 0.102517  [ 6432/150000]\n",
      "loss: 0.304820  [ 9632/150000]\n",
      "loss: 0.304388  [12832/150000]\n",
      "loss: 0.348208  [16032/150000]\n",
      "loss: 0.283727  [19232/150000]\n",
      "loss: 0.224174  [22432/150000]\n",
      "loss: 0.248286  [25632/150000]\n",
      "loss: 0.171392  [28832/150000]\n",
      "loss: 0.333460  [32032/150000]\n",
      "loss: 0.215929  [35232/150000]\n",
      "loss: 0.464962  [38432/150000]\n",
      "loss: 0.294077  [41632/150000]\n",
      "loss: 0.113324  [44832/150000]\n",
      "loss: 0.438956  [48032/150000]\n",
      "loss: 0.241568  [51232/150000]\n",
      "loss: 0.232145  [54432/150000]\n",
      "loss: 0.128801  [57632/150000]\n",
      "loss: 0.176702  [60832/150000]\n",
      "loss: 0.139668  [64032/150000]\n",
      "loss: 0.310488  [67232/150000]\n",
      "loss: 0.191115  [70432/150000]\n",
      "loss: 0.529208  [73632/150000]\n",
      "loss: 0.200157  [76832/150000]\n",
      "loss: 0.149077  [80032/150000]\n",
      "loss: 0.245926  [83232/150000]\n",
      "loss: 0.403088  [86432/150000]\n",
      "loss: 0.359345  [89632/150000]\n",
      "loss: 0.141843  [92832/150000]\n",
      "loss: 0.471597  [96032/150000]\n",
      "loss: 0.180352  [99232/150000]\n",
      "loss: 0.329302  [102432/150000]\n",
      "loss: 0.178884  [105632/150000]\n",
      "loss: 0.307717  [108832/150000]\n",
      "loss: 0.320711  [112032/150000]\n",
      "loss: 0.304022  [115232/150000]\n",
      "loss: 0.200830  [118432/150000]\n",
      "loss: 0.360545  [121632/150000]\n",
      "loss: 0.108607  [124832/150000]\n",
      "loss: 0.649257  [128032/150000]\n",
      "loss: 0.172650  [131232/150000]\n",
      "loss: 0.247416  [134432/150000]\n",
      "loss: 0.245176  [137632/150000]\n",
      "loss: 0.280069  [140832/150000]\n",
      "loss: 0.198995  [144032/150000]\n",
      "loss: 0.171004  [147232/150000]\n",
      "Checkpoint loss:0.254306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95     45004\n",
      "         1.0       0.83      0.09      0.17      4996\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.87      0.55      0.56     50000\n",
      "weighted avg       0.90      0.91      0.87     50000\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.237327 \n",
      "\n",
      "loss: 0.232882  [   32/150000]\n",
      "loss: 0.764913  [ 3232/150000]\n",
      "loss: 0.151035  [ 6432/150000]\n",
      "loss: 0.306634  [ 9632/150000]\n",
      "loss: 0.283350  [12832/150000]\n",
      "loss: 0.341236  [16032/150000]\n",
      "loss: 0.310044  [19232/150000]\n",
      "loss: 0.241709  [22432/150000]\n",
      "loss: 0.181696  [25632/150000]\n",
      "loss: 0.186803  [28832/150000]\n",
      "loss: 0.296525  [32032/150000]\n",
      "loss: 0.215257  [35232/150000]\n",
      "loss: 0.496996  [38432/150000]\n",
      "loss: 0.343655  [41632/150000]\n",
      "loss: 0.184293  [44832/150000]\n",
      "loss: 0.395373  [48032/150000]\n",
      "loss: 0.142499  [51232/150000]\n",
      "loss: 0.187817  [54432/150000]\n",
      "loss: 0.116616  [57632/150000]\n",
      "loss: 0.186490  [60832/150000]\n",
      "loss: 0.150410  [64032/150000]\n",
      "loss: 0.323363  [67232/150000]\n",
      "loss: 0.241799  [70432/150000]\n",
      "loss: 0.472317  [73632/150000]\n",
      "loss: 0.204902  [76832/150000]\n",
      "loss: 0.199815  [80032/150000]\n",
      "loss: 0.179286  [83232/150000]\n",
      "loss: 0.390299  [86432/150000]\n",
      "loss: 0.374544  [89632/150000]\n",
      "loss: 0.100932  [92832/150000]\n",
      "loss: 0.313016  [96032/150000]\n",
      "loss: 0.252597  [99232/150000]\n",
      "loss: 0.255444  [102432/150000]\n",
      "loss: 0.150570  [105632/150000]\n",
      "loss: 0.237108  [108832/150000]\n",
      "loss: 0.248209  [112032/150000]\n",
      "loss: 0.370817  [115232/150000]\n",
      "loss: 0.200653  [118432/150000]\n",
      "loss: 0.329721  [121632/150000]\n",
      "loss: 0.105407  [124832/150000]\n",
      "loss: 0.667600  [128032/150000]\n",
      "loss: 0.179190  [131232/150000]\n",
      "loss: 0.228593  [134432/150000]\n",
      "loss: 0.221336  [137632/150000]\n",
      "loss: 0.260484  [140832/150000]\n",
      "loss: 0.156521  [144032/150000]\n",
      "loss: 0.196335  [147232/150000]\n",
      "Checkpoint loss:0.182184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95     45004\n",
      "         1.0       0.72      0.20      0.31      4996\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.82      0.59      0.63     50000\n",
      "weighted avg       0.90      0.91      0.89     50000\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235628 \n",
      "\n",
      "loss: 0.271354  [   32/150000]\n",
      "loss: 0.692999  [ 3232/150000]\n",
      "loss: 0.109214  [ 6432/150000]\n",
      "loss: 0.312505  [ 9632/150000]\n",
      "loss: 0.376925  [12832/150000]\n",
      "loss: 0.288039  [16032/150000]\n",
      "loss: 0.307083  [19232/150000]\n",
      "loss: 0.245903  [22432/150000]\n",
      "loss: 0.198305  [25632/150000]\n",
      "loss: 0.177439  [28832/150000]\n",
      "loss: 0.289279  [32032/150000]\n",
      "loss: 0.313337  [35232/150000]\n",
      "loss: 0.487518  [38432/150000]\n",
      "loss: 0.291060  [41632/150000]\n",
      "loss: 0.165305  [44832/150000]\n",
      "loss: 0.338165  [48032/150000]\n",
      "loss: 0.157312  [51232/150000]\n",
      "loss: 0.151044  [54432/150000]\n",
      "loss: 0.115481  [57632/150000]\n",
      "loss: 0.153951  [60832/150000]\n",
      "loss: 0.188663  [64032/150000]\n",
      "loss: 0.291344  [67232/150000]\n",
      "loss: 0.227277  [70432/150000]\n",
      "loss: 0.536659  [73632/150000]\n",
      "loss: 0.176852  [76832/150000]\n",
      "loss: 0.192769  [80032/150000]\n",
      "loss: 0.197818  [83232/150000]\n",
      "loss: 0.497218  [86432/150000]\n",
      "loss: 0.391104  [89632/150000]\n",
      "loss: 0.105853  [92832/150000]\n",
      "loss: 0.343049  [96032/150000]\n",
      "loss: 0.158706  [99232/150000]\n",
      "loss: 0.250734  [102432/150000]\n",
      "loss: 0.165507  [105632/150000]\n",
      "loss: 0.203858  [108832/150000]\n",
      "loss: 0.314096  [112032/150000]\n",
      "loss: 0.419261  [115232/150000]\n",
      "loss: 0.200454  [118432/150000]\n",
      "loss: 0.249234  [121632/150000]\n",
      "loss: 0.152392  [124832/150000]\n",
      "loss: 0.694486  [128032/150000]\n",
      "loss: 0.145370  [131232/150000]\n",
      "loss: 0.262886  [134432/150000]\n",
      "loss: 0.281213  [137632/150000]\n",
      "loss: 0.313153  [140832/150000]\n",
      "loss: 0.181757  [144032/150000]\n",
      "loss: 0.179102  [147232/150000]\n",
      "Checkpoint loss:0.182184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95     45004\n",
      "         1.0       0.75      0.18      0.29      4996\n",
      "\n",
      "    accuracy                           0.91     50000\n",
      "   macro avg       0.83      0.59      0.62     50000\n",
      "weighted avg       0.90      0.91      0.89     50000\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235221 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    model, optimizer, min_loss, checkpoint = train_loop(dataloader_train, model, loss, optimizer, min_loss, checkpoint)\n",
    "    test_loop(dataloader_test, model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77eeb4ec-fc53-43a4-a7c5-322d5a604925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final checkpoint model loss: 0.18218375742435455\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final checkpoint model loss: {min_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b3261-2f68-4316-b8c9-0aa836cd1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall is less than ideal, but given this dataset is fairly imbalanced toward 0 for the label."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
